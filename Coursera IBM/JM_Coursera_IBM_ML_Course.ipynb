{"cells": [{"metadata": {}, "cell_type": "code", "source": "\"\"\"Install relevant libraries\"\"\"\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import NullFormatter\nimport pandas as pd\nimport numpy as np\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import jaccard_score, f1_score, log_loss\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nimport sklearn.tree as tree\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\n%matplotlib inline", "execution_count": 18, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"Retreive datasets\"\"\"\n!wget -O loan_train.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/loan_train.csv\n!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "--2022-06-24 06:22:59--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/loan_train.csv\nResolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\nConnecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 23101 (23K) [text/csv]\nSaving to: \u2018loan_train.csv\u2019\n\nloan_train.csv      100%[===================>]  22.56K  --.-KB/s    in 0s      \n\n2022-06-24 06:23:00 (95.7 MB/s) - \u2018loan_train.csv\u2019 saved [23101/23101]\n\n--2022-06-24 06:23:02--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv\nResolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\nConnecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3642 (3.6K) [text/csv]\nSaving to: \u2018loan_test.csv\u2019\n\nloan_test.csv       100%[===================>]   3.56K  --.-KB/s    in 0s      \n\n2022-06-24 06:23:02 (46.7 MB/s) - \u2018loan_test.csv\u2019 saved [3642/3642]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"Load in and clean data for further use\"\"\"\ndef dataLoader(csvfile): \n    \"\"\"Takes csvfile and processes it in the manner previously used in the test case\"\"\"\n    print(\"Loading: {}\".format(csvfile))\n    df = pd.read_csv(csvfile)\n    df['due_date'] = pd.to_datetime(df['due_date'])\n    df['effective_date'] = pd.to_datetime(df['effective_date'])\n    df['dayofweek'] = df['effective_date'].dt.dayofweek\n    df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n    df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)\n    df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n    df.groupby(['education'])['loan_status'].value_counts(normalize=True)\n    Feature = df[['Principal','terms','age','Gender','weekend']]\n    Feature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\n    Feature.drop(['Master or Above'], axis = 1,inplace=True)\n    X = Feature\n    y = df['loan_status'].values\n    X= preprocessing.StandardScaler().fit(X).transform(X)\n    print(\"Finished Loading: {}\".format(csvfile))\n    return df, X, y\n\ntrain_df, train_X, train_y = dataLoader('loan_train.csv')\ntest_df, test_X, test_y = dataLoader('loan_test.csv')\n    ", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Loading: loan_train.csv\nFinished Loading: loan_train.csv\nLoading: loan_test.csv\nFinished Loading: loan_test.csv\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"K Nearest Neighbour - data split\"\"\"\nX_train_k, X_test_k, y_train_k, y_test_k = train_test_split(train_X, train_y, test_size = 0.33, random_state = 4)\n", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Train set sizes: (231, 8) and (231,)\nTest set sizes: (115, 8) and (115,)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"K Nearest Neighbour - identifying best k\"\"\"\n\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\n\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train_k,y_train_k)\n    yhat=neigh.predict(X_test_k)\n    mean_acc[n-1] = metrics.accuracy_score(y_test_k, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test_k)/np.sqrt(yhat.shape[0])\n\nprint(\"Highest accuracy occurs at k = {}\".format(mean_acc.argmax()))\n", "execution_count": 8, "outputs": [{"output_type": "stream", "text": "Highest accuracy occurs at k = 6\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"K nearest neighbour - best k on test set\"\"\"\nkbest = mean_acc.argmax()\nneigh = KNeighborsClassifier(n_neighbors = kbest).fit(test_X,test_y)\nyhat_KNN = neigh.predict(test_X)", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"Decision Tree\"\"\"\n\nTree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\nTree.fit(train_X, train_y)\nyhat_Tree = Tree.predict(test_X)", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"Support Vector Machine\"\"\"\nclf = svm.SVC(kernel='rbf')\nclf.fit(train_X, train_y) \nyhat_SVM = clf.predict(test_X)", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"Logistic Regression\"\"\"\nLR = LogisticRegression(C=0.01, solver='liblinear').fit(train_X, train_y)\nyhat_LR = LR.predict(test_X)", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\"\"\"Evaluation for the different methods using various metrics\"\"\"\nfor (yh, method) in zip((yhat_KNN, yhat_Tree, yhat_SVM, yhat_LR), ('KNN', 'Tree', 'SVM', 'LR')): \n    j = jaccard_score(test_y, yh, pos_label = \"COLLECTION\")\n    f = f1_score(test_y, yh, pos_label = \"COLLECTION\")\n    llty = np.zeros_like(test_y, dtype = float)\n    posMask = test_y == 'COLLECTION'\n    llty[posMask] = 1\n    llyhkn = np.zeros_like(yh, dtype = float)\n    posMask = yh == 'COLLECTION'\n    llyhkn[posMask] = 1\n    l = log_loss(llty, llyhkn)\n    print(\"Method \\t Jaccard \\t F1 Score \\t Log Loss \\n\")\n    print(\"{} \\t {} \\t {} \\t {} \\n\".format(method, j, f, l))", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Method \t Jaccard \t F1 Score \t Log Loss \n\nKNN \t 0.47619047619047616 \t 0.6451612903225806 \t 7.03578032455609 \n\nMethod \t Jaccard \t F1 Score \t Log Loss \n\nTree \t 0.2 \t 0.3333333333333333 \t 7.675298450673303 \n\nMethod \t Jaccard \t F1 Score \t Log Loss \n\nSVM \t 0.0 \t 0.0 \t 9.594119361501672 \n\nMethod \t Jaccard \t F1 Score \t Log Loss \n\nLR \t 0.0 \t 0.0 \t 8.954497583865733 \n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "\"KNN is the best method\"", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.12", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}